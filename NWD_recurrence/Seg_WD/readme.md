# **基于切分的新词发现**
	【算法及代码来源】基于切片的新词发现，https://kexue.fm/archives/3913
	【引用】苏剑林. (Aug. 18, 2016). 《【中文分词系列】 2. 基于切分的新词发现 》[Blog post]. Retrieved from https://kexue.fm/archives/3913
	-【想法思路】文本片段的凝固值大于一定程度时，片段可能成词，然后考虑它的边界熵；如果片段的凝固度低于一定值，即该文本片段不成词，从而进行分词。
	-【算法思路】设a,b是语料中相邻两字，统计(a,b)成对出现的次数#(a,b)，继而估计它的频率P(a,b)，分别统计a,b出现的次数#a，#b，然后估计它们的频率P(a)，P(b)，
	判断P(a,b)/(P(a)*p[b]) < α（α是给定的大于1的阈值），则在语料中将这两个字断开，实现对原始语料初步的分词，完成分词后统计词频，根据词频进行筛选。
	
	-【特点】只用了频数和凝固度，去掉了计算量最大的边界熵，计算凝固度时只需要计算二字片段的凝固度，但理论上能够得到任意长度的词语。
	
	-【劣势】凝固度不高的词语在α太大时会导致切错。
	